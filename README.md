# Supervised Machine Learning: Regression and Classification  
*By Andrew Ng (Coursera - DeepLearning.AI)*

This repository contains my personal working files and notes from the [Supervised Machine Learning: Regression and Classification](https://www.coursera.org/learn/machine-learning) course by Andrew Ng, hosted on Coursera.  

---

## 📚 Course Overview

This course covers the foundations of supervised machine learning using real-world examples. It teaches:
- **Linear regression** for continuous outputs
- **Logistic regression** for classification
- **Gradient descent** optimization
- **Overfitting and underfitting**
- **Performance evaluation** (precision, recall, F1)
- **Vectorization** for performance

---

## 🗂️ Repository Structure
supervised-ml-andrew-ng/
│
├── week1_linear_regression/
│ ├── univariate_linear_regression.ipynb
│ ├── cost_function_and_gradient_descent.py
│ └── README.md
│
├── week2_multivariate_regression_regularization/
│ ├── feature_scaling_and_normalization.ipynb
│ ├── multivariate_regression.py
│ ├── regularization_intro.md
│ └── README.md
│
├── week3_logistic_regression_classification/
│ ├── logistic_regression_from_scratch.ipynb
│ ├── sigmoid_function_and_gradient.py
│ ├── decision_boundary_visualization.ipynb
│ └── README.md
│
├── utils/
│ ├── plotting.py
│ └── gradient_helpers.py
│
├── .gitignore
└── README.md ← (you are here)

---

## 📈 Topics Covered by Week

### ✅ Week 1 – Linear Regression with One Variable
- Cost function (MSE)
- Gradient descent intuition
- Implementation from scratch
- Plotting loss surface

### ✅ Week 2 – Multiple Features and Regularization
- Feature scaling
- Multivariate linear regression
- L2 Regularization (Ridge Regression)
- Overfitting vs Underfitting

### ✅ Week 3 – Classification with Logistic Regression
- Sigmoid function
- Cross-entropy loss
- Binary classification
- Decision boundary visualization
- Performance metrics (Precision, Recall, F1)

---

## Learning Goals

- Implement foundational ML algorithms from scratch
- Improve understanding of cost functions & gradient descent
- Practice clean coding and documentation of ML workflows
- Build an intuition for regularization and classification performance



---

⭐️ *If this repo helps you, consider starring it or using it as a reference for your own ML learning journey!*
